---
title: Redis Compressed Lists
date: 2013-08-31 18:54 CEST
tags: redis, performance, ruby
published: false
---

Redis is great for storing certain types of data that do not do well in a relational database.
It is great for storing caches and statistics too.
However, the storage capacity of redis is capped by RAM size, so care is required when storing large amounts of data in it.

I will show you a trick to reduce memory usage and improve the speed of the redis *list* type for storing series-type data (e.g. time series).
Redis compresses small lists with zip, reducing their memory usage by 10-40% for numeric data.
The exact list size threshold at which redis stops compressing is defined by the `list-max-ziplist-entries` setting and defaults to 512.

Here is the trick: we will transparently partition a list into many small lists of `list-max-ziplist-entries` size.
By storing lists under the threshold, we take advantage of redis' ability to compress them.

Here is a memory usage benchmark:

<%= article_image_tag 'bm-512.png', class: 'img-responsive' %>

To benchmark access speed let's try some random accesses on a large list:

<% code 'bash' do %>
<% end %>

Speed savings *and* memory savings. This is because a redis list is a linked list, so getting ranges out of it is slow. However, it is much faster for a partitioned list, since we can get to the start and end of each partition in `O(1)`.


I published a [Ruby implementation][redis-stats-int_series.rb] of this approach for int and time series.

Is anyone doing something similar? I am curious to hear other approaches

[redis-stats-int_series.rb]: https://github.com/glebm/redis_stats/blob/master/lib/redis_stats/int_series.rb

*Thanks [@ddtrejo](https://twitter.com/ddtrejo) for your edits and suggestions!*